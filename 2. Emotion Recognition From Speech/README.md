

# **Emotion Recognition from Speech ğŸ¤ğŸ’¬**

![task 2](https://github.com/user-attachments/assets/5e568b54-f82a-4ffe-90d1-886ae0dc5f01)


## **Overview**
This project aims to recognize emotions from speech using a Long Short Term Memory (LSTM) model. It was developed during my internship as a Machine Learning Engineer at CodeAlpha.

## **Demo**
Check out the demo video showcasing the web app's capabilities in recognizing emotions from audio files!


https://github.com/user-attachments/assets/37a8fd29-6b5a-4e83-8121-c76826e0c988



## **Features**
- Predicts emotions such as **Fear**, **Sadness**, and more from speech audio.
- User-friendly web interface for easy interaction.
- Built using advanced machine learning techniques for accurate predictions.

## **Project Lifecycle**
1. **Data Collection** ğŸ“Š
   - Gathered diverse audio samples for training the model.

![DADADAD](https://github.com/user-attachments/assets/a79d6113-a975-4d5a-8f0b-f35c360c3319)


2. **Data Preprocessing** ğŸ§¹
   - Cleaned and prepared the audio data for analysis.

![SPECTROGRAM](https://github.com/user-attachments/assets/8264e14d-9de5-4aa8-b178-919eaeaca29e)



3. **Data Augmentation** ğŸ”„
   - Enhanced the dataset by creating variations of existing audio samples.
  
![AUGMONTED](https://github.com/user-attachments/assets/1a922a3e-a4a1-474f-8a43-f1144610d8a5)


4. **Feature Extraction** ğŸ”
   - Identified and extracted key features from the audio files.
  

5. **Model Training** ğŸ‹ï¸â€â™‚ï¸
   - Trained the LSTM model on the processed data.

![model training](https://github.com/user-attachments/assets/a8a5131a-7812-4f8a-9203-de8772447584)


6. **Model Evaluation** ğŸ“ˆ
   - Assessed the model's performance and improved accuracy.
![LSTM](https://github.com/user-attachments/assets/9e7d373c-9f86-4c2e-91e9-5f0c01ca553d)


7. **Save the Model** ğŸ’¾
   - Saved the trained model for future predictions.

![model](https://github.com/user-attachments/assets/f7743b4b-11a3-4adf-813a-b00265ed82ef)


9. **Model Deployment** ğŸš€
   - Deployed the model as a web application for user access.

![Capture](https://github.com/user-attachments/assets/a6452e2e-b8b5-4a5a-969e-16a2310e0747)


## **Getting Started**
To run this project locally, follow these steps:

### **Prerequisites**
- Python 3.x
- Required libraries (listed in `requirements.txt`)

### **Installation**
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/emotion-recognition-speech.git
   cd emotion-recognition-speech
   ```

2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. Run the web app:
   ```bash
   python app.py
   ```

## **ğŸ“ Repository Structure**
```
emotion-recognition-speech/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                # Main application file
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ codealpha-emotion-recognition-from-speech.pdf
    â”œâ”€â”€ Emotion-Recognition-From-Speech.pdf             # Document for steps taken to make this project
â”œâ”€â”€ jupyter notebook/
â”‚   â””â”€â”€  codealpha-emotion-recognition-from-speech.ipynbb       # To Do Experimentation with data
â”œâ”€â”€ LSTM model/
â”‚   â””â”€â”€ lstm_model.h5              # LSTM Model
â”œâ”€â”€ test audio files/
â”‚   â”œâ”€â”€ OAF_base_sad.wav
    â”œâ”€â”€ YAF_back_fear.wav             # Audio used for model prediction
â”œâ”€â”€ requirements.txt      # Required Python packages
â”œâ”€â”€ README.md             # Project documentation
â””â”€â”€ ...
```


## **Acknowledgments**
Thanks to #CodeAlpha for the opportunity to work on this exciting project!


